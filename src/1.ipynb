{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy==1.23.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (2025.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: sympy in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sk315\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "2025-03-16 16:22:23.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.933 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.935 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.935 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:23.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: streamlit in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (1.43.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch==2.1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch==2.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch==2.1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from torch==2.1.0) (2025.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from rank-bm25) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from sympy->torch==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sk315\\workspace\\cai_assignment\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 16:22:26.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.967 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.967 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.973 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-16 16:22:26.973 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance pandas numpy==1.23.5 sentence-transformers faiss-cpu==1.7.4\n",
    "%pip install rank-bm25 scikit-learn streamlit nltk torch==2.1.0\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import streamlit as st\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Function to download and preprocess financial data for a given company ticker\n",
    "def download_financials(ticker, start_date, end_date):\n",
    "    company = yf.Ticker(ticker)\n",
    "    data = company.history(start=start_date, end=end_date)\n",
    "    data = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "    data.ffill(inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to structure and clean data for RAG model retrieval\n",
    "def structure_data_for_retrieval(data):\n",
    "    # Convert the index to datetime if not already in that format\n",
    "    data.index = pd.to_datetime(\n",
    "        data.index, errors=\"coerce\"\n",
    "    )  # Coerce errors to NaT (Not a Time)\n",
    "    # Handle any missing dates or columns by forward-filling or backward-filling\n",
    "    data.ffill(inplace=True)\n",
    "\n",
    "    # Extract Year and Quarter from the datetime index\n",
    "    data[\"Year\"] = data.index.year\n",
    "    data[\"Quarter\"] = data.index.quarter\n",
    "\n",
    "    # Group data by Year and Quarter, then apply aggregation functions\n",
    "    data_grouped = data.groupby([\"Year\", \"Quarter\"]).agg(\n",
    "        {\n",
    "            \"Open\": \"mean\",  # Average opening price\n",
    "            \"High\": \"mean\",  # Average highest price\n",
    "            \"Low\": \"mean\",  # Average lowest price\n",
    "            \"Close\": \"mean\",  # Average closing price\n",
    "            \"Volume\": \"sum\",  # Total volume of shares traded\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optionally: You can reset index if needed for easier manipulation\n",
    "    data_grouped.reset_index(inplace=True)\n",
    "    return data_grouped\n",
    "\n",
    "\n",
    "def advanced_multi_stage_rag_model(financial_data, chunk_size=\"sentence\"):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Generate structured financial reports from the data\n",
    "    financial_reports = []\n",
    "    for (year, quarter), group in financial_data.groupby([\"Year\", \"Quarter\"]):\n",
    "        report = {\n",
    "            \"year\": year,\n",
    "            \"quarter\": quarter,\n",
    "            \"open\": group[\"Open\"].mean(),\n",
    "            \"close\": group[\"Close\"].mean(),\n",
    "            \"high\": group[\"High\"].max(),\n",
    "            \"low\": group[\"Low\"].min(),\n",
    "            \"volume\": group[\"Volume\"].sum(),\n",
    "        }\n",
    "        financial_reports.append(report)\n",
    "\n",
    "    # Group text chunks for each financial metric\n",
    "    text_chunks = []\n",
    "    for report in financial_reports:\n",
    "        text_chunks.append(\n",
    "            [\n",
    "                f\"For {report['year']} Q{report['quarter']} the company had:\",\n",
    "                f\" - Average Opening Price: {report['open']:.2f}\",\n",
    "                f\" - Average Closing Price: {report['close']:.2f}\",\n",
    "                f\" - Highest Price: {report['high']:.2f}\",\n",
    "                f\" - Lowest Price: {report['low']:.2f}\",\n",
    "                f\" - Total Trading Volume: {report['volume']}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Flatten grouped chunks for tokenization\n",
    "    grouped_text_chunks = [\" \".join(chunk) for chunk in text_chunks]\n",
    "\n",
    "    # Initialize BM25\n",
    "    tokenized_chunks = [\n",
    "        word_tokenize(chunk)\n",
    "        for chunk in grouped_text_chunks\n",
    "        if chunk not in string.punctuation\n",
    "    ]\n",
    "    bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "    # Embed each chunk using the pre-trained model\n",
    "    embeddings = model.encode(grouped_text_chunks, convert_to_tensor=True)\n",
    "\n",
    "    # Create a FAISS index to store and retrieve the embeddings\n",
    "    dim = embeddings.shape[1]\n",
    "    faiss_index = faiss.IndexFlatL2(dim)\n",
    "    faiss_index.add(embeddings.cpu().numpy())  # Add embeddings to FAISS index\n",
    "\n",
    "    return faiss_index, bm25, grouped_text_chunks, model\n",
    "\n",
    "\n",
    "def extract_year_and_quarter(query):\n",
    "    \"\"\"\n",
    "    Extracts the year and quarter from the user's query using regex.\n",
    "    Supports formats like 'Q1 2023', '2023 Q1',\n",
    "    'What is the volume for Q1 2023?', etc.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(Q[1-4])\\s*(\\d{4})\", query)\n",
    "    # Match Q1 2023, Q2 2023, etc.\n",
    "\n",
    "    if not match:\n",
    "        # Try the reverse: 2023 Q1\n",
    "        match = re.search(r\"(\\d{4})\\s*(Q[1-4])\", query)\n",
    "        # Match 2023 Q1, 2024 Q2, etc.\n",
    "\n",
    "    if match:\n",
    "        if \"q\".lower() in match.group(2).lower():\n",
    "            return match.group(2), match.group(1)\n",
    "        # (quarter, year) to match \"Q1 2023\"\n",
    "        else:\n",
    "            return match.group(1), match.group(2)\n",
    "    else:\n",
    "        return None, None  # No match found\n",
    "\n",
    "\n",
    "# Multi-Stage Retrieval with BM25 + FAISS + Re-ranking\n",
    "def multi_stage_retrieve_and_rerank(query, faiss_index, bm25, text_chunks, model, k=1):\n",
    "    # Stage 1: BM25-based Retrieval\n",
    "    tokenized_query = [\n",
    "        token for token in word_tokenize(query) if token not in string.punctuation\n",
    "    ]\n",
    "\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top_k_indices = np.argsort(bm25_scores)[-k:][::-1]\n",
    "    # Get top-k BM25 indices\n",
    "    # Retrieve the top-k BM25 results (keyword-based)\n",
    "    bm25_top_k_chunks = [text_chunks[i] for i in bm25_top_k_indices]\n",
    "\n",
    "    # Stage 2: FAISS-based Retrieval\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    D, T = faiss_index.search(query_embedding.cpu().numpy(), k)\n",
    "    # Retrieve using FAISS\n",
    "\n",
    "    # Retrieve the top-k FAISS results (semantic-based)\n",
    "    faiss_top_k_chunks = [text_chunks[i] for i in T[0]]\n",
    "\n",
    "    # Stage 3: Combine results from BM25 and FAISS\n",
    "    combined_chunks = list(set(bm25_top_k_chunks + faiss_top_k_chunks))\n",
    "\n",
    "    # Stage 4: Re-ranking by cosine similarity\n",
    "    combined_embeddings = model.encode(combined_chunks, convert_to_tensor=True)\n",
    "    cosine_similarities = cosine_similarity(\n",
    "        query_embedding.cpu().numpy(), combined_embeddings.cpu().numpy()\n",
    "    )\n",
    "\n",
    "    # Re-rank the combined chunks based on cosine similarity\n",
    "    reranked_chunks = [\n",
    "        combined_chunks[i] for i in np.argsort(cosine_similarities[0])[::-1]\n",
    "    ]\n",
    "    # Extract year and quarter from the query to filter the relevant chunks\n",
    "    quarter, year = extract_year_and_quarter(query)\n",
    "    filtered_chunks = []\n",
    "    filtered_chunks = []\n",
    "    for chunk in reranked_chunks:\n",
    "        if f\"{year}\" in chunk and f\"{quarter}\" in chunk:\n",
    "            filtered_chunks.append(chunk)\n",
    "        elif f\"{year}\" in chunk and quarter is None:\n",
    "            filtered_chunks.append(chunk)\n",
    "        elif f\"{quarter}\" in chunk and year is None:\n",
    "            filtered_chunks.append(chunk)\n",
    "\n",
    "    # Return safely with a fallback if no match is found\n",
    "    return filtered_chunks, cosine_similarities[0]\n",
    "\n",
    "\n",
    "# Return top-k re-ranked chunks\n",
    "\n",
    "\n",
    "def validate_user_query(query):\n",
    "    # Input-side guardrail: Remove offensive,\n",
    "    # irrelevant, or non-financial queries\n",
    "    if not query or len(query.split()) < 2:\n",
    "        return (\n",
    "            False,\n",
    "            \"\"\"Query is too short or empty.\n",
    "    Please enter a more specific query.\"\"\",\n",
    "        )\n",
    "\n",
    "    # Example of checking for harmful content\n",
    "    harmful_keywords = [\"hack\", \"malware\", \"scam\", \"fraud\"]\n",
    "    if any(keyword in query.lower() for keyword in harmful_keywords):\n",
    "        return (\n",
    "            False,\n",
    "            \"\"\" Query contains harmful content.\n",
    "            Please ask a legitimate question.\"\"\",\n",
    "        )\n",
    "\n",
    "    # Example of checking if the query is related to financial topics\n",
    "    financial_keywords = [\n",
    "        \"revenue\",\n",
    "        \"profit\",\n",
    "        \"volume\",\n",
    "        \"quarter\",\n",
    "        \"earnings\",\n",
    "        \"sales\",\n",
    "        \"stock price\",\n",
    "        \"opening price\",\n",
    "        \"closing price\",\n",
    "        \"trading volume\",\n",
    "        \"high price\",\n",
    "        \"low price\",\n",
    "        \"average\",\n",
    "        \"increase\",\n",
    "        \"decrease\",\n",
    "    ]\n",
    "    if not any(keyword.lower() in query.lower() for keyword in financial_keywords):\n",
    "        return (\n",
    "            False,\n",
    "            \"\"\"Query does not seem to relate to financial topics.\n",
    "            Please ask a relevant financial question like\n",
    "            'What was the average stock price for Q1 2023?'\n",
    "            or 'What is the EPS for Q2 2023?'\"\"\",\n",
    "        )\n",
    "\n",
    "    # Check if the query asks for data that\n",
    "    # can be computed from available financial data\n",
    "    valid_question_keywords = [\n",
    "        \"average\",\n",
    "        \"increase\",\n",
    "        \"decrease\",\n",
    "        \"what\",\n",
    "        \"how\",\n",
    "        \"stock price\",\n",
    "        \"volume\",\n",
    "        \"trading volume\",\n",
    "        \"quarter\",\n",
    "        \"year\",\n",
    "    ]\n",
    "    if not any(keyword.lower() in query.lower() for keyword in valid_question_keywords):\n",
    "        return (\n",
    "            False,\n",
    "            \"\"\"Query is not formulated in a way that can be\n",
    "            answered based on the financial data we have.\n",
    "            Please ask something like\n",
    "            'What was the average opening stock price for Q1 2023?'\n",
    "            or 'How did the trading volume change in Q2 2023?'\"\"\",\n",
    "        )\n",
    "\n",
    "    return True, \"\"\n",
    "\n",
    "\n",
    "def extract_metric_from_query(query):\n",
    "    # Use regex to extract the financial metric from the query\n",
    "    # Example: 'What was the volume for Q4 2023'\n",
    "    match = re.search(\n",
    "        r\"(volume|open|close|high|low | debt | revenue | stock price)\", query.lower()\n",
    "    )\n",
    "    print(match)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the matched metric\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_metric_from_chunk(chunk, metric):\n",
    "    print(metric, chunk)\n",
    "    match = None\n",
    "    if \"volume\" in metric.lower():\n",
    "        match = re.search(r\"total trading volume: ([\\d,]+)\", chunk.lower())\n",
    "    elif \"open\" in metric.lower() :\n",
    "        match = re.search(r\"average opening price: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"close\" in metric.lower():\n",
    "        match = re.search(r\"average closing price: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"high\" in metric.lower():\n",
    "        match = re.search(r\"highest price: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"low\" in metric.lower():\n",
    "        match = re.search(r\"lowest price: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"stock\" in metric.lower():\n",
    "        print('yes')\n",
    "        match = re.search(r\"highest price: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"profit\" in metric.lower() or \"earnings\" in metric.lower():\n",
    "        match = re.search(r\"profit: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"low\" in metric.lower():\n",
    "        match = re.search(r\"lowest price: ([\\d\\.]+)\", chunk.lower())\n",
    "    elif \"average\" in metric.lower():\n",
    "        match = re.search(r\"average opening ([\\w\\s]+): ([\\d\\.]+)\", chunk.lower())\n",
    "    print(match, \"sach\")\n",
    "    return match.group(1) if match else \"Metric not found\"\n",
    "\n",
    "\n",
    "# Guardrail for output validation\n",
    "def filter_output_answer(answer, query, model, threshold=0.3):\n",
    "    metric = extract_metric_from_query(query)\n",
    "    # If no specific metric is found in the query, return an error\n",
    "    if not metric:\n",
    "        return \"No relevant metric found in the query.\"\n",
    "\n",
    "    # Output-side guardrail: Ensure answer is not hallucinated or misleading\n",
    "    answer_embedding = model.encode([answer], convert_to_tensor=True)\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    cosine_sim = cosine_similarity(\n",
    "        query_embedding.cpu().numpy(), answer_embedding.cpu().numpy()\n",
    "    )[0][0]\n",
    "    if cosine_sim < threshold:\n",
    "        return \"\"\"The answer seems irrelevant or hallucinated.\n",
    "            Please ask a different query.\"\"\"\n",
    "    # If the metric matches, return the answer; else, return an error\n",
    "    final_ans = extract_metric_from_chunk(answer, metric)\n",
    "    return final_ans\n",
    "\n",
    "\n",
    "# Test function for running pre-defined questions (Updated for Streamlit)\n",
    "def run_test_cases(faiss_index, bm25, text_chunks, model):\n",
    "    # Define test questions based on the financial reports and data\n",
    "    test_questions = {\n",
    "        \"High Confidence Relevant Financial Question\": {\n",
    "            \"question\": \"What was the Volume for Q4 2023?\",\n",
    "            \"expected\": \"Volume for Q4 2023 is 200350.\",\n",
    "            # Replace with actual data\n",
    "        },\n",
    "        \"Low Confidence Relevant Financial Question\": {\n",
    "            \"question\": \"What was the stock opening price for Q3 2023?\",\n",
    "            \"expected\": \"stock opening price for Q3 2023 is $104.5.\",\n",
    "            # Replace with actual data\n",
    "        },\n",
    "        \"Irrelevant Question\": {\n",
    "            \"question\": \"What is the capital of France?\",\n",
    "            \"expected\": \"Irrelevant, should return no relevant answers.\",\n",
    "        },\n",
    "        \"Quarterly Profit Check\": {\n",
    "            \"question\": \"What was the profit for Q1 2023?\",\n",
    "            \"expected\": \"\"\"No direct profit data available,\n",
    "            but you can check stock data for Q1 2023.\"\"\",\n",
    "        },\n",
    "        \"Company Debt Query\": {\n",
    "            \"question\": \"What is the total debt for the company in Q2 2023?\",\n",
    "            \"expected\": \"\"\" Debt information not explicitly available,\n",
    "            but stock data for Q2.\"\"\",\n",
    "        },\n",
    "        \"General Revenue Query\": {\n",
    "            \"question\": \"What was the total volume for the company?\",\n",
    "            \"expected\": \"\"\" volume information is available for\n",
    "            specific quarters (e.g., Q1 2023, Q4 2023).\"\"\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    st.write(\"### Test Questions & Results\")\n",
    "    results = []\n",
    "\n",
    "    for test_name, test_case in test_questions.items():\n",
    "        query = test_case[\"question\"]\n",
    "\n",
    "        reranked_chunks = multi_stage_retrieve_and_rerank(\n",
    "            query, faiss_index, bm25, text_chunks, model, k=3\n",
    "        )\n",
    "\n",
    "        # Filter the results\n",
    "        if reranked_chunks:\n",
    "            filtered_answer = filter_output_answer(reranked_chunks[0], query, model)\n",
    "            results.append((query, filtered_answer))\n",
    "        else:\n",
    "            results.append((query, \"No relevant answers found.\"))\n",
    "\n",
    "    # Display the test results\n",
    "    for query, filtered_answer in results:\n",
    "        st.write(f\"**Question:** {query}\")\n",
    "        st.write(f\"**Answer:** {filtered_answer}\")\n",
    "        st.write(\"---\")\n",
    "\n",
    "\n",
    "# Main UI with Streamlit\n",
    "def main():\n",
    "    # st.title(\"Multi-Stage RAG Model for Financial\n",
    "    # Data Retrieval with Guardrails and Testing\")\n",
    "\n",
    "    # Inputs for the UI\n",
    "    ticker = st.text_input(\"Enter the Stock Ticker:\", \"TGT\")\n",
    "    start_date = st.date_input(\"Start Date:\", pd.to_datetime(\"2023-03-15\"))\n",
    "    end_date = st.date_input(\"End Date:\", pd.to_datetime(\"2025-03-15\"))\n",
    "\n",
    "    # Download and preprocess the data\n",
    "    financial_data = download_financials(ticker, start_date, end_date)\n",
    "    financial_data.head()\n",
    "    # Structure the data for easier retrieval\n",
    "    structured_data = structure_data_for_retrieval(financial_data)\n",
    "\n",
    "    # Initialize and run the multi-stage RAG model\n",
    "    faiss_index, bm25, text_chunks, model = advanced_multi_stage_rag_model(\n",
    "        structured_data\n",
    "    )\n",
    "\n",
    "    # Accept user query\n",
    "    query = st.text_input(\"Enter your query:\", \"\")\n",
    "\n",
    "    if query:\n",
    "        # Validate the query (Input-side guardrail)\n",
    "        is_valid, error_message = validate_user_query(query)\n",
    "        if not is_valid:\n",
    "            st.error(error_message)\n",
    "        else:\n",
    "            reranked_chunks, reranked_scores = multi_stage_retrieve_and_rerank(\n",
    "                query, faiss_index, bm25, text_chunks, model, k=3\n",
    "            )\n",
    "\n",
    "            # Display the relevant chunks and confidence score\n",
    "            st.write(\"### Top Retrieved Answers:\")\n",
    "            for i, chunk in enumerate(reranked_chunks, 1):\n",
    "                # Filter the output (Output-side guardrail)\n",
    "                filtered_answer = filter_output_answer(chunk, query, model)\n",
    "                st.write(\n",
    "                    f\"**Answer {i}:** {filtered_answer}, confidence label: {reranked_scores[i-1]:.2f}\"\n",
    "                )\n",
    "\n",
    "    # Add a button to test only test cases\n",
    "    if st.button(\"Run Test Cases\"):\n",
    "        st.write(\"### Running Test Cases\")\n",
    "        run_test_cases(faiss_index, bm25, text_chunks, model)\n",
    "\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
